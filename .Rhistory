theme_bw()
#autoplot rmse
autoplot(all_models, metric = "rmse") +
labs(y = "Root Mean Squared Error (rmse)") +
scale_color_manual(values = c("black", "#cc0000")) +
theme_bw()
youtube_data$target
summary(youtube_data)
#r-squared
rmse(truth_against_pred, truth = target, estimate = .pred)
#r-squared
rsq_trad(truth_against_pred, truth = target, estimate = .pred)
#r-squared
rsq(truth_against_pred, truth = target, estimate = .pred)
#rmse
rmse(truth_against_pred, truth = target, estimate = .pred)
#previous code needed
lm_model <-
linear_reg() %>%
set_engine("lm")
#others
lm_wflow <-
lm_wflow %>%
add_recipe(recipe_for_with_inter) %>%
add_model(lm_model)
View(nonuni_a)
fit_lm_interaction <- fit(lm_wflow, youtube_training)
#others
lm_wflow <-
lm_wflow %>%
add_recipe(recipe_for_with_inter) %>%
add_model(lm_model)
#others
lm_wflow <-
workflow() %>%
add_recipe(recipe_for_with_inter) %>%
add_model(lm_model)
fit_lm_interaction <- fit(lm_wflow, youtube_training)
save(fit_lm_interaction, file = "data/fit_lm_interaction.rda")
load("data/fit_lm_interaction.rda")
#check coefficients
tidy(fit_lm_interaction)
#check coefficients
l <- tidy(fit_lm_interaction)
l
View(l)
l %>%
select(estimate)
l %>%
mutate(estimate = abs(estimate))
l %>%
mutate(estimate = abs(estimate)) %>%
select(estimate) %>%
max()
l %>%
mutate(estimate = abs(estimate)) %>%
filter(!is.na(estimate))
l %>%
mutate(estimate = abs(estimate)) %>%
filter(!is.na(estimate)) %>%
arrange(desc(estimate))
#data wrangling to find the factor with the greatest
#absolute estimate
l %>%
mutate(estimate = abs(estimate)) %>%
filter(!is.na(estimate)) %>%
arrange(desc(estimate))
l %>%
filter(estimate = comment_count)
l %>%
filter(estimate == comment_count)
l %>%
filter(estimate == "comment_count")
l %>%
filter(term == comment_count)
l %>%
filter(term == "comment_count")
l %>%
filter(term == "comment_count")
library(stringr)
l %>%
filter(stringr::str_starts(terms, "category"))
l %>%
filter(stringr::str_starts(term, "category"))
l %>%
filter(stringr::str_starts(term, "category")) %>%
arrange(estimate)
l %>%
filter(stringr::str_starts(term, "category")) %>%
filter(stringr::str_length(term) < 15)
l %>%
filter(stringr::str_starts(term, "category")) %>%
filter(stringr::str_length(term) < 15) %>%
arrange(desc(estimate))
l %>%
filter(stringr::str_starts(term, "category")) %>%
filter(stringr::str_length(term) < 15) %>%
arrange(desc(estimate)) %>%
tail(3)
l %>%
filter(stringr::str_starts(term, "category")) %>%
filter(stringr::str_length(term) < 15) %>%
arrange(desc(estimate)) %>%
head(3)
View(youtube_data)
#correlation comment count and view count
youtube_data %>%
select(comment_count, view_count)
#correlation comment count and view count
youtube_data %>%
select(comment_count, view_count) %>%
cor()
truth_against_pred
truth_against_pred %>%
filter(target < 0.2)
truth_against_pred_0.2 <- truth_against_pred %>%
filter(target < 0.2)
rsq(truth_against_pred_0.2, truth = target, estimate = .pred)
truth_against_pred_0.2 <- truth_against_pred %>%
filter(target < 0.15)
rsq(truth_against_pred_0.2, truth = target, estimate = .pred)
rmse(truth_against_pred_0.2, truth = target, estimate = .pred)
rsq(truth_against_pred_0.2, truth = target, estimate = .pred)
truth_against_pred_0.2 <- truth_against_pred %>%
filter(target < 0.1)
rsq(truth_against_pred_0.2, truth = target, estimate = .pred)
rmse(truth_against_pred_0.2, truth = target, estimate = .pred)
truth_against_pred_0.2 <- truth_against_pred %>%
filter(target < 0.05)
rsq(truth_against_pred_0.2, truth = target, estimate = .pred)
truth_against_pred_0.2 <- truth_against_pred %>%
filter(target < 0.5)
rsq(truth_against_pred_0.2, truth = target, estimate = .pred)
View(truth_against_pred_0.2)
skim(youtube_data)
#set seed for reproducibility
set.seed(123)
#data
youtube_data <- read_parquet("data/youtube_metrics.parquet")
#number of rows and columns
nrow(youtube_data)
ncol(youtube_data)
summary(youtube_data)
skim(youtube_data)
skim_without_charts(youtube_data)
#getting rid of missing observations in duration
youtube_data <- youtube_data %>%
filter(!is.na(duration_seconds))
#creating derived variables
youtube_data <- youtube_data %>%
mutate(released_date = as_date(publishedAt),
hour_released = hour(publishedAt),
day_week_released = wday(publishedAt),
time_release_trending = as.numeric(trending_date - released_date))
#converting day of the week to strings
youtube_data <- youtube_data %>%
mutate(day_week_released = if_else(day_week_released == 1,
"Sunday",
if_else(day_week_released == 2,
"Monday",
if_else(day_week_released == 3,
"Tuesday",
if_else(day_week_released == 4,
"Wednesday",
if_else(day_week_released == 5,
"Thursday",
if_else(day_week_released == 6,
"Friday",
if_else(day_week_released == 7,
"Saturday",
"None"))))))))
#checking final youtube_data
skim_without_charts(youtube_data)
#getting prediction phase data
youtube_pred <- youtube_data_split %>% training()
#getting data for EDA
youtube_eda <- youtube_data_split %>% testing()
#save final youtube_data
save(youtube_data, file = youtube_data.rda)
#save final youtube_data
save(youtube_data, file = "youtube_data.rda")
#save final youtube_data
save(youtube_data, file = "data/youtube_data.rda")
load("data/youtube_data.rda")
#creating function to analyze distribution
univar_numeric_plots <- function(col) {
#return a ggplot object
ggplot(data = youtube_eda,
#that maps the x axis to the argument
mapping = aes(x = {{col}})) +
#and makes a histogram with 100 bins
geom_histogram(bins = 100,
#personalize colors to youtube palette
fill = "#cc0000") +
#personalize theme
theme_bw() +
#title dependent on argument
labs(title = paste("Distribution of", deparse(substitute(col)), sep = " "))
}
#making plots
uni_a <- univar_numeric_plots(likes) #likes distribution
uni_b <- univar_numeric_plots(categoryId) #categoryId distribution
uni_c <- univar_numeric_plots(view_count) #view_count distribution
uni_d <- univar_numeric_plots(dislikes) #dislikes distribution
uni_e <- univar_numeric_plots(comment_count) #comment_count distribution
uni_f <- univar_numeric_plots(duration_seconds) #duration_seconds distribution
uni_g <- univar_numeric_plots(target) #target distribution
#joining with patchwork
(uni_a + uni_b + uni_c + uni_d) / (uni_e + uni_f + uni_g + uni_h)
#mode function
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
#Allocation of data ----
#set seed
set.seed(123)
#splitting data
youtube_data_split <- youtube_data %>%
#60% for prediction phase and 40$ for eda
initial_split(prop = 0.6)
#Allocation of data ----
#set seed
set.seed(123)
#splitting data
youtube_data_split <- youtube_data %>%
#60% for prediction phase and 40$ for eda
initial_split(prop = 0.6)
#getting prediction phase data
youtube_pred <- youtube_data_split %>% training()
#getting data for EDA
youtube_eda <- youtube_data_split %>% testing()
#saving data
save(youtube_pred, file = "data/youtube_pred")
#saving data
save(youtube_pred, file = "data/youtube_pred.rda")
load("data/youtube_pred.rda")
set.seed(123)
#subsetting youtube_pred data set
#to make the data set more efficient for modeling
#reasoning explained in the Rmd
youtube_modeling <- youtube_pred %>%
#getting rid of variables
select(-c(title, publishedAt,
channelId, tags,
thumbnail_link, description,
id, channelTitle,
released_date, trending_date)) %>%
#making some variables factors for better dummy conversion later
mutate(has_thumbnail = factor(has_thumbnail),
ratings_disabled = factor(ratings_disabled),
comments_disabled = factor(comments_disabled),
categoryId = factor(categoryId),
day_week_released = factor(day_week_released))
#showing first results
head(youtube_modeling, 10)
#split training-test
youtube_split <- youtube_modeling %>%
#80% for training set and 20% for test set
#stratify by outcome variable
initial_split(prop = 0.8, strata = target, breaks = 4)
#getting training set
youtube_training <- youtube_split %>% training()
#getting test set
youtube_test <- youtube_split %>% testing()
#Assesing models ----
collect_metrics(all_models) %>% filter(.metric == "rsq")
#making plot
assess_res %>%
ggplot(aes(x = target, y = .pred)) +
geom_point(alpha = .15) +
geom_abline(color = "red") +
coord_obs_pred() +
ylab("Predicted") +
theme_bw() +
labs(y = "predictions in the training set - resamples",
x = "actual values in the training set")
###plots ----
autoplot(all_models) +
scale_color_manual(values = c("black", "#cc0000")) +
theme_bw()
#making plot
assess_res %>%
ggplot(aes(x = target, y = .pred)) +
geom_point(alpha = .15) +
geom_abline(color = "red") +
coord_obs_pred() +
ylab("Predicted") +
theme_bw() +
labs(y = "predictions in the training set - resamples",
x = "actual values in the training set")
load("data/fit_lm_interaction.rda")
#check coefficients
l <- tidy(fit_lm_interaction)
l
#data wrangling to find the factor with the greatest
#absolute estimate
l %>%
mutate(estimate = abs(estimate)) %>%
filter(!is.na(estimate)) %>%
arrange(desc(estimate))
l %>%
filter(stringr::str_starts(term, "category")) %>%
filter(stringr::str_length(term) < 15) %>%
arrange(desc(estimate)) %>%
tail(3)
load("data/all_models.rda")
library(readr)
library(ggfortify)
library(arrow)
library(skimr)
library(tidymodels)
library(lubridate)
library(patchwork)
#metrics of models
collect_metrics(all_models, filter = "rmse")
#metrics of models
collect_metrics(all_models)
#metrics of models
collect_metrics(all_models) %>% filter(.metric == "rsq")
#metrics of models
collect_metrics(all_models) %>% filter(.metric == "rmse")
collect_metrics(all_models) %>% filter(.metric == "rsq")
### Models Selection
4 main models were used to fit the resamples and assess which performed the best: Linear models, lasso models, ridge models, and random forest models. For the first three type of models, each one of them had two versions: without and with pairwise interactions. In the case of random forest, two versions were also created: using the default values, and customizing the number of trees to 1000.
### Models Selection
4 main models were used to fit the resamples and assess which performed the best: Linear models, lasso models, ridge models, and random forest models. For the first three type of models, each one of them had two versions: without and with pairwise interactions. In the case of random forest, two versions were also created: using the default values, and customizing the number of trees to 1000.
collect_metrics(all_models) %>% filter(.metric == "rsq")
### Models Selection
4 main models were used to fit the resamples and assess which performed the best: Linear models, lasso models, ridge models, and random forest models. For the first three type of models, each one of them had two versions: without and with pairwise interactions. In the case of random forest, two versions were also created: using the default values, and customizing the number of trees to 1000.
knitr::opts_chunk$set(
warning = FALSE, message = FALSE, echo = FALSE
)
library(readr)
library(ggfortify)
library(arrow)
library(skimr)
library(tidymodels)
library(lubridate)
library(patchwork)
library(stringr)
load("data/all_models.rda")
load("data/rf_customized_models.rda")
load("data/fit_lm_interaction.rda")
load("data/final_fit.rda")
set.seed(123)
#set seed for reproducibility
set.seed(123)
#data
youtube_data <- read_parquet("data/youtube_metrics.parquet")
#number of rows and columns
nrow(youtube_data)
ncol(youtube_data)
#getting rid of missing observations in duration
youtube_data <- youtube_data %>%
filter(!is.na(duration_seconds))
#skimming data
skim_without_charts(youtube_data)
#creating additional variables
youtube_data <- youtube_data %>%
mutate(released_date = as_date(publishedAt),
hour_released = hour(publishedAt),
day_week_released = wday(publishedAt),
time_release_trending = as.numeric(trending_date - released_date))
#converting day of the week to strings
youtube_data <- youtube_data %>%
mutate(day_week_released = if_else(day_week_released == 1,
"Sunday",
if_else(day_week_released == 2,
"Monday",
if_else(day_week_released == 3,
"Tuesday",
if_else(day_week_released == 4,
"Wednesday",
if_else(day_week_released == 5,
"Thursday",
if_else(day_week_released == 6,
"Friday",
if_else(day_week_released == 7,
"Saturday",
"None"))))))))
#EDA split
youtube_data_split <- youtube_data %>%
initial_split(prop = 0.6)
youtube_pred <- youtube_data_split %>% training()
youtube_eda <- youtube_data_split %>% testing()
#creating function to analyze distribution
univar_numeric_plots <- function(col) {
ggplot(data = youtube_eda,
mapping = aes(x = {{col}})) +
geom_histogram(bins = 100,
fill = "#cc0000") +
theme_bw() +
labs(title = paste("Distribution of", deparse(substitute(col)), sep = " "))
}
#making plots
uni_a <- univar_numeric_plots(likes)
uni_b <- univar_numeric_plots(categoryId)
uni_c <- univar_numeric_plots(view_count)
uni_d <- univar_numeric_plots(dislikes)
uni_e <- univar_numeric_plots(comment_count)
uni_f <- univar_numeric_plots(duration_seconds)
uni_g <- univar_numeric_plots(target)
uni_h <- univar_numeric_plots(hour_released)
#joining with patchwork
(uni_a + uni_b + uni_c + uni_d) / (uni_e + uni_f + uni_g + uni_h)
#transforming variables
youtube_eda <- youtube_eda %>%
mutate(likes = log(likes, base = 10),
view_count = log(view_count, base = 10),
comment_count = log(comment_count, base = 10),
dislikes = log(dislikes, base = 10),
duration_seconds = log(duration_seconds, base = 10))
#making plots
uni_a_1 <- univar_numeric_plots(likes)
uni_b_1 <- univar_numeric_plots(categoryId)
uni_c_1 <- univar_numeric_plots(view_count)
uni_d_1 <- univar_numeric_plots(dislikes)
uni_e_1 <- univar_numeric_plots(comment_count)
uni_f_1 <- univar_numeric_plots(duration_seconds)
uni_g_1 <- univar_numeric_plots(target)
uni_h_1 <- univar_numeric_plots(hour_released)
#joining with patchwork
(uni_a_1 + uni_b_1 + uni_c_1 + uni_d_1) / (uni_e_1 + uni_f_1 + uni_g_1 + uni_h_1)
ggplot(data = youtube_eda,
mapping = aes(x = time_release_trending)) +
geom_histogram(bins = 100,
fill = "#cc0000") +
theme_bw() +
labs(title = "Distribution of the number of days from \nrelease to becoming trending",
x = "number of days") +
theme(plot.title = element_text(size = 10))
#mode function
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
#highlight highest bar plot-function
highlight_max_bar <- function(col) {
col1 <- as_vector(youtube_eda %>% select({{col}}))
h <- Mode(col1)
if(h == 18565) {
h <- as_date(h)
meanwhile <- youtube_eda %>%
mutate(max = if_else({{col}} == h,
TRUE,
FALSE)) %>%
ggplot(aes(x = {{col}}, fill = max)) +
scale_fill_manual(values = c("#6e6e6e", "#cc0000")) +
geom_bar(show.legend = FALSE) +
theme_bw() +
labs(x = deparse(substitute(col)))
meanwhile
} else {
h <- h
meanwhile <- youtube_eda %>%
mutate(max = if_else({{col1}} == h,
TRUE,
FALSE)) %>%
ggplot(aes(x = {{col1}}, fill = max)) +
scale_fill_manual(values = c("#6e6e6e", "#cc0000")) +
geom_bar(show.legend = FALSE) +
theme_bw() +
labs(x = deparse(substitute(col)))
meanwhile
}
}
nonuni_a <- highlight_max_bar(day_week_released)
nonuni_b <- highlight_max_bar(comments_disabled)
nonuni_c <- highlight_max_bar(ratings_disabled)
nonuni_d <- highlight_max_bar(has_thumbnail)
nonuni_e <- highlight_max_bar(released_date)
#puting them together with patchwork
nonuni_e / (nonuni_a + nonuni_b + nonuni_c + nonuni_d)
#function to make bivariate numeric plots
biv_numeric <- function(col) {
ggplot(data = youtube_eda,
mapping = aes(x = {{col}},
y = target)) +
geom_jitter(alpha = 0.1, color = "#6e6e6e") +
geom_smooth(se = FALSE, color = "#cc0000") +
theme_bw() +
labs(title = paste("Scatterplot of target vs", deparse(substitute(col)), sep = " "))
}
#applying function to make plots
biv_a <- biv_numeric(dislikes)
biv_b <- biv_numeric(comment_count)
biv_c <- biv_numeric(duration_seconds)
biv_d <- biv_numeric(hour_released)
biv_e <- biv_numeric(time_release_trending)
#together with patchwork
biv_e / (biv_a + biv_b) / (biv_c + biv_d)
#function to make bivariate numeric plots
biv_numeric <- function(col) {
ggplot(data = youtube_eda,
mapping = aes(x = {{col}},
y = target)) +
geom_jitter(alpha = 0.1, color = "#6e6e6e") +
geom_smooth(se = FALSE, color = "#cc0000") +
theme_bw() +
labs(title = paste("Scatterplot of target vs", deparse(substitute(col)), sep = " "))
}
#applying function to make plots
biv_a <- biv_numeric(dislikes)
biv_b <- biv_numeric(comment_count)
biv_c <- biv_numeric(duration_seconds)
biv_d <- biv_numeric(hour_released)
biv_e <- biv_numeric(time_release_trending)
#together with patchwork
biv_e / (biv_a + biv_b) / (biv_c + biv_d)
#together with patchwork
biv_e / (biv_a + biv_b) / (biv_c + biv_d)
